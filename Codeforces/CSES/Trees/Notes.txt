Various Operations:
Finding Diameter : O(n)
    Other scenario: 
    start dfs from 1(root) to find the farthest end point(lets call it u)
    start 2nd dfs from u to find the farthest end point(lets call it v). u and v represents two different endpoints of the diameter
    For any node x, the maximum distance to any other node is: max(dist(x, u), dist(x, v)).
Finding the sum of distances from node to all nodes in its subtree
Finding LCA(u,v) : O(logn)
Binary Lifting 
    Precomputation: O(n*20) which is O(n)
    liftNode(u,k) O(logk) --> in worst case O(logn)
evalDepth() --> O(n) using dp[] 
evalSubtreeSize() --> O(n) using dp[]


Binary Lifting:
    If no of rows is much larger than no of columns, then how should we construct the matrix? 
    I mean why is it preferred to have a dimension with lower value along the row side and dimension with higher value along the column side

    This is related to matrix layout and memory access patterns
    Row-Major vs Column-Major Order
	â€¢	C++ stores 2D arrays in row-major order, meaning:
	â€¢	Elements in the same row are stored contiguously in memory

    ðŸ§  Analogy: Bookshelf
    Imagine youâ€™re scanning a shelf of books:
	â€¢	Row-major: books in the same row are side by side (fast to scan left to right).
	â€¢	Accessing vertically (like a stack on different shelves) is slow â€” you have to jump across memory.



Subordinates:
    Simple recursion, used memoisation to optimise

Tree Matching [Excellent Problem]
    Recursion + Memoisation 
    optimisation trick : calculated prefix and suffix sums to find sum from (0 to i-1) and (i+1 to n-1) in O(1)
    
Tree Diameter       -- evaluting diameter       
                            sorting method takes O(nlogn)
                            manually traversing the heights[] to find best 2 heights : O(n)
    Recursion + memoisation
    Took tree as an() input in adj list just like graph(UG). 
    Recursion Logic: If the diamter passes through the root, ans would be 2+max 2 depths of its subtrees, if only 1 subtree exists then 1+subtree's depth and if no subtree then 0
        If the diameter doesn't pass through the root, compute the diamter for each subtree and then select the max out of them
        Pick the max amongst the 2 above options
    Memoisation: solve() calls getDepth() for each node multiple times. Thus inorder to save on the repeated computations, we would save the depth for each node in Dp array, so that if the same function call is made in the future, instead of computing it again, we would directly pick the value


Tree Distance 1 [Excellent Problem] 
    Uses tree's diameter concept. The farthest distance of a node will be its distance from either of the endpoints of the diameter 
    We first find the 2 endpoints of the diameter. 
    Start a dfs(1) from 1 assuming 1 is the root, to find the farthest possible node. Keep track of the distance of each node from sv 
    after the dfs call, iterate over the dist[] to find the max dist and the corresponding node
    Start another dfs(u) and find the farthest possible node. lets call it v. Again use a dist_u[] to keep track of the distance of each node from u 
    Final dfs(v) to get the distance of each node from v 



    N<=1e5, so we have to come up with O(N) or O(NlogN) approach
    Brute force approach: 
        O(n^2) For every node I would perform a bfs/dfs and track the distance I've travelled. N nodes and for each node O(n) time.
        ans for each node is essentially the depth of the tree rooted at that node. So if we evalute the depth of the tree considering each node as root, then we'll be compute the ans.
        But evaluating depth of a tree is O(n) operation, and performing this n times considerign each node as root, will lead to O(n^2) solution

    Sol1: (more intuitive)
        â€¢	In a tree, the longest path between two nodes is called the diameter of the tree.
        â€¢	For a node u, its maximum distance to any other node is either:
        â€¢	Distance to one endpoint of the diameter
        â€¢	Or distance to the other endpoint

        âœ… So basically:
            â€¢	Find two farthest points in the tree (the two endpoints of the diameter).
            â€¢	Then for each node, maximum distance = max(distance to endpoint1, distance to endpoint2)

    Sol2 : (less intuitive)
        Task is to determine for each node the maximum distance to another node.
        Precomputed the depth of tree at each node in O(n)
        Used prefixMax and suffixMax array to get the max value from the left and right in O(1)
        in addition to sv & parent, we also propagated partial_ans variable which helps us in computing ans for each node
        partial_ans for a node is the 1 + max depth of any of its siblings


Tree Distance 2 [Excellent Problem] 
    precomputations + rerooting technique

    Task is to determine for each node the sum of the distances from the node to all other nodes.
    N <= 1e5, so we need to find an O(N) or O(NlogN) solution
    Sol1: Very first thought, if we find distance b/w every pair of nodes(using floyd O(n^3)), that can help. But this is inefficient
    Sol2: or Run a DFS N times for each node and calculate the sum of distance for each node --> This is O(N^2), O(N) for each DFS call and there are N nodes
    
    Sol3: 
    ðŸ”¥ Key Idea:

    Instead of recomputing distances from scratch for every node (which would be too slow), we use two DFS traversals:

    1. First DFS (Postorder Traversal):
        â€¢	Calculate:
        â€¢	subtree_size[node]: How many nodes are there in the subtree rooted at node.
        â€¢	dp[node]: Sum of distances from node to all nodes in its subtree.

    â¸»

    2. Second DFS (Rerooting Technique):
        â€¢	Move the root from a node to its child and update the distance sums smartly.
        â€¢	If you know the answer for a node, you can compute the answer for its children in O(1) time.

    The core idea:
    ans[child] = ans[parent] + (n - 2 * subtree_size[child])
    (When you move the root from parent to child, distances to nodes in childâ€™s subtree decrease by 1, and distances to nodes outside childâ€™s subtree increase by 1.)

    ðŸš€ Plan:
	â€¢	First DFS:
	        Compute dp[node] and subtree_size[node]
	â€¢	Second DFS:
	        Reroot and compute final answers for all nodes
    
    Time Complexity:
	â€¢	First DFS: O(n)
	â€¢	Second DFS: O(n)
	â€¢	Total: O(n) âœ…

    âš¡ Final Key:
    Step         What it does
    dfs1         Find subtree sizes and initial distances
    dfs2         Use rerooting to find answer for every node

    dp[u] += dp[v] + subtree_size[v];
    can you explain how this condition holds true?

        ðŸ§  First, Recall What dp[u] and subtree_size[u] Mean:
            â€¢	dp[u]: The sum of distances from node u to all nodes in its subtree.
            â€¢	subtree_size[u]: The total number of nodes in the subtree rooted at u, including u itself.

        ðŸ”¥ Now, letâ€™s break it down:

            When youâ€™re doing DFS from u to v, v is a child of u.
            You already know:
            â€¢	dp[v] â†’ The sum of distances from v to all nodes in its subtree.
            â€¢	subtree_size[v] â†’ The number of nodes in the subtree rooted at v.

            Now, when youâ€™re at u and you want to merge the information from v into u:
            â€¢	To reach any node in the subtree rooted at v starting from u, you must:
            â€¢	Move one extra step from u to v, and
            â€¢	Then from v to the destination node.

        So:

        âœ… For each node in vâ€™s subtree:
        	â€¢	The distance from u = (1 step to v) + (distance from v to that node
        Thus:
        	â€¢	The total extra distance = subtree_size[v] (because you add 1 for each node
        dp[u] += dp[v] + subtree_size[v];
        means:
        	â€¢	Add all the distances already calculated from v (dp[v]),
        	â€¢	Plus 1 step for each node in vâ€™s subtree (subtree_size[v]).

    
    Proof : ans[child] = ans[parent] + (n - 2 * subtree_size[child])

        Suppose:
        â€¢	n = total number of nodes
        â€¢	subtree_size[child] = number of nodes inside the subtree rooted at child
        â€¢	Thus, n - subtree_size[child] = number of nodes outside the subtree
        
        When moving the root from parent to child:
        â€¢	For each node in the childâ€™s subtree:
        â€¢	Distance decreases by 1 â†’ total effect = -subtree_size[child]
        â€¢	For each node outside the childâ€™s subtree:
        â€¢	Distance increases by 1 â†’ total effect = +(n - subtree_size[child])

        âœï¸ Total change in distance sum:
        Total Change = (nodes outside child) + (nodes inside child)
                = (n - subtree_size[child]) - subtree_size[child]
                = n - 2 * subtree_size[child]

        Thus,
        ans[child] = ans[parent] + (n - 2 * subtree_size[child]);


Company Queries 1
    binary lifting 
        precomputation : O(n+1 * 20)  approx O(n) operation
        liftNode(u,k): O(logK) operation

    Binary Lifting: If I precompute 2^ith parent for each node then I can easily compute kth parent for each node 

Company Queries 2 [Excellent Problem] 
    Finding LCA -- O(logn) operation

    LCA(lowest common ancestor) in logN time
    LCA(u,v) ==> the node at the lowest level which is common in the path from u to root and v to root is the LCA
    level(lca(u,v)) <= min(level(u),level(v))
    assume v is at the lower level and is more closer to the lca 
    I know the difference in levels of u and v, let's call it diff. I can jump diff from U(this can be done in logn using binary lifting) and now both the nodes will be at the same level
    or the other case is U and V would become equivalent to each other( in the case when V was an ancestor of U)
        1
 
            V
    U

    First make a jump of diff so that both nodes u and v are at the same level, assuming v lies closer to the LCA. Obviously after making the jump if U and V become equiovalent to each other, then V is the LCA

        1
        LCA
    newU   V

    NOW U AND V are the same level and they are not equivalent. There is some difference in the levels of LCA and newU, let's call it X
    Now we dont know this X, but one thing is sure that X lies in range of [1,level(newU)]. 
    We can apply binary search to find the lca node, lets say for mid m, we take a jump from new_u and V. if we reach the same node, that node could be our lca and we update our range [1, mid-1] to find the best possible answer 
    else [mid+1,level(newU)]

Distance Queries
    Based on LCA
    q queries --> have to evaluate the distance b/w 2 nodes u and V
    the path from u to v always passes through the lca(u,v)
    dist(u,v) = depth[u] + depth[v] - 2*depth[lca]


Counting paths              {Excellent Problem}
    Based on LCA 
    Some standard properties of a tree:
    1. There always exists a unique path b/w 2 nodes u and V
    2. Tree is always connected in nature
    3. Path b/w 2 nodes always passes through their lca 
    4. Also if you consider a path b/w 2 nodes u and v, lca node has got the lowest height amonst all the nodes in the path
    i.e the lca will always be at the highest point, or if you consider from the root side(it will have the lowest height amonst all nodes in the path)
    
Subtree Queries [Excellent Problem] 
    Task: Sum of the values in the subtree of node S 

    Euler Tour + Segment Tree 
    Sum of the values in the subtree of node s is equivalent to finding the sum of the values in the segment startTime[s], endTime[s]
    Euler tour will give us the startTime and endTime for each node. So we have node, time relation 
    We also have node, values relation 
    Using the above 2, we can construct time, values relation 
    NOTE: Assume we have N nodes 0 to N-1 and timer starts from 0, the startTime for each node will also be in range 0 to N-1 
    N sized value array, N sized startTime array(storing the start time for each node), N sized timer-values array 
    Build sum Segment Tree to compute the sum of a segment in O(logN)



PathQueries [Excellent problem] Implementation Pending
    Task: Sum of the values in the path from root node 1 to node S 

    Euler Tour + Segment Tree 
    Here we have to find sum of value in the path from root to Node s 
    Sum of the values in the path from root to node s is equivalent to finding the sum of the values of the segment startTime[1] and endTime[s]-1
    Here there is small change in the way startTime and endTime is computed. Here we also update the endTime while exiting a node. In the prev problem subtree queries, the endTime remained the same 
    The main part is understanding why sum of the segment startTime[1] to endTime[s]-1 gives us the sum of the values from root to node s
    All the nodes in the path from node 1(root) to node s have start time >= root's startTime and startTime <= endTime[s]. All the other nodes that are not part of the path and have startTime > starTime[1] & start time <= endTime[s] also end before i.e their endtime is < endTime[s].
    Plus the nodes whose startTime whose > endTime[s]. We dont need to care about them

    NOTE: Main benefit of using a segment Tree in this problem is it allows us to answer each query in O(logN) time as compared to O(N) approach for the brute force solution + it also allows us to accomodate updates 
    Segment Tree allows update which takes just O(logN) time 
    That is why segment Tree is the best ds when dealing with updates and answering multiple queries 


PathQueries 2 [Pending]
    Task: Find the maximum value on the path b/w node A and node B 
    Heavy light decomposition

Distinct colors [Good Problem]
    New concept : SMALL TO LARGE MERGING
    for each node we'll have a set that tracks the distinct colors in its subtree 
    i.e set<int> color[MAXN] 
    colors array of size N where each index is a set for the subtree rooted at ith node 
    Each node will have its own set for their subtrees 
    NOTE Merging a small set of size M into a large Set of size N takes O(MlogN)
    AND MERGING 2SETS OF SIZE M AND N INTO A NEW SET TAKES O(MLOG(M+N)), ASSUMING M > N otherwise IT WILL BE O(NLOG(M+N))
    SWAPPING IS AN O(1) OPERATION EVEN FOR SWAPPING SETS AS WELL  

Finding a Centroid [Good Problem]
    Uses Central decomposition technique [Read about it]
    https://www.youtube.com/watch?v=e-mxm5bykrQ&ab_channel=Senior  

    A centroid is a node such that when it is appointed as the root of the tree, each of its child subtree size is atmost [n/2] nodes
    All the trees have a centroid
    Brute force is to check the subtree size for each child, considering all the nodes as root one by one
    For 1 call -> Tc is O(N)
    for N nodes -> TC would be O(N^2)
    optimised approach using central decomposition:
        Start with any node as the root, check all its child subtree sizes. If the max(childSubtree size) <= [n/2], then the root node is your centroid 
        Otherwise if there exists a childNode whose subtree size is > [n/2] (centroid will lie in that subtree), recurse on that childNode
        TC: O(N) for computing the subtree size of each node 
        and O(N) for 2nd dfs call to find the centroid
        Overall: O(N) + O(N);



Centroid decomposition [Pending]
https://www.youtube.com/watch?v=w_kmxeeEv5c&ab_channel=LearntoCodewithCodeChef

What is a centroid?


Properties:
For any given tree, the centroid always exists
    start with any arbitrary vertex and check whether it satisfies the property. If yes, we're done, otherwise there exists only one adjacent subtree with more than N/2 nodes.
    Consider the adjacent vertex u in that subtree and apply the same argument. Repeat till you find the centroid

Centroid Decomposition:
    Decomposing the original tree to get the Centroid tree

    def decompose(root, centroid_parent = -1):
        centroid = find_centroid(root)
        if centroid_parent != -1:
            add_edge_in_centroid_tree(centroid_parent, centroid)
        for(adjacent_edge, adjacent_vertex) in G[centroid]:
            delete_edge(adjacent_edge)
            decompose(adjacent_vertex, centroid)


    decompose() returns a rooted tree with centroid of the original tree as the root

    original_tree, centroid_tree
    find the centroid of the original tree, that centroid becomes the root of your centroid tree
    recurse to centroid's child and call decompose on those child nodes to decompose the child's subtrees 
    The centroid of those child's subtrrees becomes children of centroid in your centroid tree 

    properties of centroid tree:            {https://www.youtube.com/watch?v=w_kmxeeEv5c&ab_channel=LearntoCodewithCodeChef}
    1. The structure of the centroid tree is very different from the original tree and an edge in the centroid tree might not represent an edge in the original tree 
    2. The centroid tree contains all the N nodes of the original tree   
    3. The height of the centroid tree is at most O(logN)
        Since at each step, the new trees formed by removing the centroid have size at most N/2, the maximum no of levels would be O(logN)
    4. Consider any two arbitrary vertices A and B and the path betweeen them in the originaln tree can be broken down into A --> C and C --> B where C is the LCA of nodes A and B in the centroid tree
         In the original tree, the first time A and B got disconnected was when we removed vertex C. Hence A--B = A--C + C--B
    5. In a tree, we can have N^2 paths(NC2)
        We decompose the given tree into O(NlogN) different paths (from each centroid to all the vertices in the corresponding part) such that any path 
        is a concatenation of two different paths from this set 

        The claim here is all the N^2 paths in your original tree can be broken down into A,C and B,C 
        where C is the LCA of A and B in the centroid tree and both these paths A,C and B,C are part of this O(NlogN) paths 

        There are atmost O(N) special paths(whose one endpoint is Centroid and other endpoint is any other vertex) at each level in your centroid tree. 
        Since there logN levels, total no of paths are O(NlogN)


        We'll prepocess the info for these NlogN paths. This will help us to answer each query very efficiently 
        Since the path A,B can be broken down into A,C and B,C where C is the lca(A,B0 in the centroid tree, we would already have info for these A,C and B,C paths since these are part of those O(NlogN) paths 

        usecases:
            dist(A,B) = Dist(A,C) + Dist(B,C)
            minWtEdge(A,B) = min(minWtEdge(A,C), minWtEdge(B,C))
            




Revision
    Tree Matching
    Tree Diameter: 
        2 choices: diameter either can pass through the root, or will belong to any of it's subtree
        Why dp array for storing depths? In order to avoid repeated calculations of max depth for each node in the calcDiamater()
        getDepth() is repeateadly called in the calcDiamter()
        We can also memoise the diamter results for each node. diameter[i] will represents the diamter of tree rooted at ith node 
    Tree Distance 1
    Tree Distance 2     
    Company Queries1 --> binary Lifing
    Company Queries2 --> LCA (sol1: binaryLifting + binary search TC O(log2n), sol2: using binaryLifting TC: O(logn))
    Distance Queries: --> distance between 2 nodes u and v is depth[u] + depth[v] - 2*depth[v]
    Counting Paths